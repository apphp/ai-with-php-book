# Classification of ML Algorithms



### Supervised Learning

Algorithms that learn from labeled data, where each example has input data and a corresponding label.

*   TASK (Regression):

    * Linear Regression
    * Logistic Regression
    * Polynomial Regression
    * Support Vector Machines (SVM)
    * Support Vector Regression (SVR)
    * Lasso Regression
    * Ridge Regression
    * Bayesian Linear Regression:


* TASK (Classification):
  * Decision Trees
  * Random Forests
  * k-Nearest Neighbors (KNN)
  * Naive Bayes Classifier
  * Neural Networks

### Unsupervised Learning

Algorithms that work with unlabeled data to identify structures and hidden patterns.

* TASK (Clustering):
  * k-Means
  * Hierarchical Clustering
  * DBSCAN (Density-Based Spatial Clustering of Applications with Noise)
  * Gaussian Mixture Models (GMM)
* TASK (Dimensionality Reduction):
  * Principal Component Analysis (PCA)
  * Linear Discriminant Analysis (LDA)
  * t-SNE (t-distributed Stochastic Neighbor Embedding)
  * Autoencoders



### Semi-Supervised Learning

Algorithms that use a small amount of labeled data combined with a large amount of unlabeled data.

• Self-training Algorithms

• Co-training

• Graph-based Methods



### Reinforcement Learning

Algorithms that learn through interactions with an environment, using rewards or penalties to improve behavior.

• Q-Learning

• SARSA (State-Action-Reward-State-Action)

• Deep Q-Networks (DQN)

• Policy Gradients

• Proximal Policy Optimization (PPO)

* Bayesian Q-Learning.

### Distributed Learning

Algorithms that split the training process across multiple machines or devices to handle large datasets and speed up computations.

• Distributed Stochastic Gradient Descent (Distributed SGD)

• Federated Learning

• MapReduce for ML

• Horovod (for deep learning models)

• Apache Spark MLlib



By Techniques

### Heuristic Methods

Methods that use approximations to find solutions for complex problems.

• Genetic Algorithms

• Ant Colony Optimization

• Particle Swarm Optimization

### Ensemble Methods

Methods that combine several models to improve predictions.

• Random Forests

• Boosting

* Gradient Boosting

• Bagging (Bootstrap Aggregation)

• Stacking



### Bayesian Methods (New Subcategory)

• Bayesian Networks

• Bayesian Linear Regression

• Bayesian Optimization

• Bayesian Q-Learning

• Bayesian Neural Networks\


